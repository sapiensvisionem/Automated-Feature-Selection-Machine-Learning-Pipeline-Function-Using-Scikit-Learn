{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function design:\n",
    "    input: string of model, data, location where results should be stored <br>\n",
    "    output: model object, evaluation metrics <br>\n",
    "    features: feature selection schemes and grid search\n",
    "    model-specific optimal pipeline:\n",
    "        1. Logistic Regression: backward elimination, L1 and L2 norm; interaction finder\n",
    "        2. LDA/QDA: backward elimination; interaction finder\n",
    "        3. SVM: L1 norm (LinearSVC) and filtering\n",
    "        4. Random Forest:  filtering, 2 stage \n",
    "        5. Boosting: filtering, 2 stage\n",
    "        6. Gradient Boosting:  always allow higher depth to allow finding interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classification_FS_ML_Pipeline(model, data, location):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.svm import SVC\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.externals import joblib\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.gaussian_process.kernels import RBF\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "    from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "    from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score, balanced_accuracy_score, cohen_kappa_score, f1_score, recall_score, precision_score, average_precision_score, brier_score_loss\n",
    "    \n",
    "    # define y an x\n",
    "    y = data.iloc[:,0] # response variable needs to be the first column\n",
    "    X = data.iloc[:,1:]\n",
    "    \n",
    "    # split train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # fit a standard scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit_transform(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # initialize models\n",
    "    logistic = LogisticRegression()\n",
    "    \n",
    "    # feature selection\n",
    "    selector = RFE(estimator, \n",
    "                   cv=5, \n",
    "                   step=1,\n",
    "                  scoring='roc_auc')\n",
    "    \n",
    "    # grid search\n",
    "    CV_clf_1a = GridSearchCV(estimator=clf_1a, \n",
    "                      param_grid={'n_estimators': [300,500, 700],\n",
    "                                  'max_features': ['auto'],\n",
    "                                  'criterion' :['gini', 'entropy'],\n",
    "                                 'max_depth':np.arange(2,11)},\n",
    "                      cv= 5, \n",
    "                      scoring = 'roc_auc')\n",
    "    pipeline_1a  = Pipeline([('feature_sele',rfecv_1a),\n",
    "                          ('clf_cv',CV_clf_1a)])\n",
    "\n",
    "    pipeline_1a.fit(X_train, y_train)\n",
    "    y_predict_1a = pipeline_1a.predict(X_test)\n",
    "    \n",
    "    # measure accuracy\n",
    "    print(\"Accuracy is: \" + str(accuracy_score(reference, predicted)))\n",
    "    print(\"F1 score is: \" + str(f1_score(reference, predicted)))\n",
    "    print(\"Precision is: \" + str(precision_score(reference, predicted)))\n",
    "    print(\"Recall is: \" + str(recall_score(reference, predicted)))\n",
    "    print(\"Kappa score is: \" + str(cohen_kappa_score(reference, predicted)))\n",
    "    print(\"AUC is: \" + str(roc_auc_score(reference, predicted)))\n",
    "    print(\"Balanced accuracy is: \" + str(balanced_accuracy_score(reference, predicted)))\n",
    "    print(confusion_matrix(y_predict, y_test))\n",
    "    \n",
    "    return pipeline_1a\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
